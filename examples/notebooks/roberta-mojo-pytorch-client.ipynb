{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright 2024 Modular, Inc: Licensed under the Apache License v2.0 with LLVM Exceptions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAX Serve and PyTorch model client example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python import Python\n",
    "from tensor import Tensor, TensorShape, TensorSpec\n",
    "from max.engine import EngineNumpyView\n",
    "\n",
    "@always_inline\n",
    "fn numpy_data_pointer[\n",
    "    type: DType\n",
    "](numpy_array: PythonObject) raises -> DTypePointer[type]:\n",
    "    var data_ptr = numpy_array.__array_interface__[\"data\"][0].__index__()\n",
    "    return DTypePointer[type](address=data_ptr)\n",
    "\n",
    "@always_inline\n",
    "fn memcpy_to_numpy[\n",
    "    type: DType\n",
    "](array: PythonObject, tensor: Tensor[type]) raises:\n",
    "    var dst = numpy_data_pointer[type](array)\n",
    "    var src = tensor._ptr\n",
    "    var length = tensor.num_elements()\n",
    "    memcpy(dst, src, length)\n",
    "\n",
    "\n",
    "@always_inline\n",
    "fn shape_to_python_list(shape: TensorShape) raises -> PythonObject:\n",
    "    var python_list = Python.evaluate(\"list()\")\n",
    "    for i in range(shape.rank()):\n",
    "        _ = python_list.append(shape[i])\n",
    "    return python_list^\n",
    "\n",
    "@always_inline\n",
    "fn get_np_dtype[type: DType](np: PythonObject) raises -> PythonObject:\n",
    "    @parameter\n",
    "    if type.is_float32():\n",
    "        return np.float32\n",
    "    elif type.is_int32():\n",
    "        return np.int32\n",
    "    elif type.is_int64():\n",
    "        return np.int64\n",
    "    elif type.is_uint8():\n",
    "        return np.uint8\n",
    "\n",
    "    raise \"Unknown datatype\"\n",
    "\n",
    "@always_inline\n",
    "fn tensor_to_numpy[\n",
    "    type: DType\n",
    "](tensor: Tensor[type], np: PythonObject) raises -> PythonObject:\n",
    "    var shape = shape_to_python_list(tensor.shape())\n",
    "    var tensor_as_numpy = np.zeros(shape, get_np_dtype[type](np))\n",
    "    _ = shape^\n",
    "    memcpy_to_numpy(tensor_as_numpy, tensor)\n",
    "    return tensor_as_numpy^\n",
    "\n",
    "@always_inline\n",
    "fn numpy_to_tensor[\n",
    "    dtype: DType\n",
    "](inout np_array: PythonObject) raises -> Tensor[dtype]:\n",
    "    var view = EngineNumpyView(np_array)\n",
    "    var size = view.spec().num_elements()\n",
    "    var ptr = DTypePointer[dtype].alloc(size)\n",
    "    memcpy(ptr, view.unsafe_ptr().bitcast[dtype](), size)\n",
    "    return Tensor[dtype](view.spec(), ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare client/inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var transformers = Python.import_module(\"transformers\")\n",
    "\n",
    "var model_name = \"roberta\"\n",
    "var model_path = \"roberta.torchscript\"\n",
    "var batch = 1\n",
    "var seqlen = 128\n",
    "\n",
    "var HF_MODEL_NAME = \"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\"\n",
    "var hf_model = transformers.AutoModelForSequenceClassification.from_pretrained(HF_MODEL_NAME)\n",
    "hf_model.config.return_dict = False\n",
    "\n",
    "# Tokenize input into input ids and mask:\n",
    "var INPUT = \"There are many exciting developments in the field of AI Infrastructure!\"\n",
    "var tokenizer = transformers.AutoTokenizer.from_pretrained(HF_MODEL_NAME)\n",
    "var raw_inputs = tokenizer(INPUT,\n",
    "    return_tensors=\"pt\", padding='max_length', truncation=True, max_length=seqlen)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from max.engine import InferenceSession\n",
    "from max.engine.tensor import EngineNumpyView\n",
    "from max.serve.kserve.client import GRPCInferenceClient\n",
    "\n",
    "var session = InferenceSession()\n",
    "var inputs = session.new_tensor_map()\n",
    "var a = raw_inputs[\"input_ids\"].detach().numpy()\n",
    "var b = raw_inputs[\"attention_mask\"].detach().numpy()\n",
    "var input_ids = numpy_to_tensor[DType.int64](a)\n",
    "var attention_mask = numpy_to_tensor[DType.int64](b)\n",
    "inputs.borrow(\"input_ids\", input_ids)\n",
    "inputs.borrow(\"attention_mask\", attention_mask)\n",
    "for key in inputs.keys():\n",
    "    print(key[] + \" : \" + str(inputs.get[DType.int64](key[])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var req_outputs = List[String](\"result0\")\n",
    "var client = GRPCInferenceClient(\"0.0.0.0:8000\", session)\n",
    "var response = client.infer(\"roberta\", \"0\", inputs, req_outputs)\n",
    "var outputs = response.get_output_tensors()\n",
    "for key in outputs.keys():\n",
    "    print(key[] + \" : \" + str(outputs.get[DType.float32](key[])))\n",
    "\n",
    "var np = Python.import_module(\"numpy\")\n",
    "var arr = tensor_to_numpy(outputs.get[DType.float32](\"result0\"), np)\n",
    "\n",
    "# Extract class prediction from output\n",
    "var predicted_class_id = arr.argmax(axis=-1)[0]\n",
    "var classification = hf_model.config.id2label[predicted_class_id]\n",
    "\n",
    "print(\"The sentiment is: \" + str(classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TODO: Add batch example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
