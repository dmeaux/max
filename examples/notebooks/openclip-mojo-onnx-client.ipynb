{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright 2024 Modular, Inc: Licensed under the Apache License v2.0 with LLVM Exceptions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAX Serve and PyTorch model client example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python import Python\n",
    "from tensor import Tensor, TensorShape, TensorSpec\n",
    "from max.engine import EngineNumpyView\n",
    "\n",
    "@always_inline\n",
    "fn numpy_data_pointer[\n",
    "    type: DType\n",
    "](numpy_array: PythonObject) raises -> DTypePointer[type]:\n",
    "    var data_ptr = numpy_array.__array_interface__[\"data\"][0].__index__()\n",
    "    return DTypePointer[type](address=data_ptr)\n",
    "\n",
    "@always_inline\n",
    "fn memcpy_to_numpy[\n",
    "    type: DType\n",
    "](array: PythonObject, tensor: Tensor[type]) raises:\n",
    "    var dst = numpy_data_pointer[type](array)\n",
    "    var src = tensor._ptr\n",
    "    var length = tensor.num_elements()\n",
    "    memcpy(dst, src, length)\n",
    "\n",
    "\n",
    "@always_inline\n",
    "fn shape_to_python_list(shape: TensorShape) raises -> PythonObject:\n",
    "    var python_list = Python.evaluate(\"list()\")\n",
    "    for i in range(shape.rank()):\n",
    "        _ = python_list.append(shape[i])\n",
    "    return python_list^\n",
    "\n",
    "@always_inline\n",
    "fn get_np_dtype[type: DType](np: PythonObject) raises -> PythonObject:\n",
    "    @parameter\n",
    "    if type is DType.float32:\n",
    "        return np.float32\n",
    "    elif type is DType.int32:\n",
    "        return np.int32\n",
    "    elif type is DType.int64:\n",
    "        return np.int64\n",
    "    elif type is DType.uint8:\n",
    "        return np.uint8\n",
    "\n",
    "    raise \"Unknown datatype\"\n",
    "\n",
    "@always_inline\n",
    "fn tensor_to_numpy[\n",
    "    type: DType\n",
    "](tensor: Tensor[type], np: PythonObject) raises -> PythonObject:\n",
    "    var shape = shape_to_python_list(tensor.shape())\n",
    "    var tensor_as_numpy = np.zeros(shape, get_np_dtype[type](np))\n",
    "    _ = shape^\n",
    "    memcpy_to_numpy(tensor_as_numpy, tensor)\n",
    "    return tensor_as_numpy^\n",
    "\n",
    "@always_inline\n",
    "fn numpy_to_tensor[\n",
    "    dtype: DType\n",
    "](inout np_array: PythonObject) raises -> Tensor[dtype]:\n",
    "    var view = EngineNumpyView(np_array)\n",
    "    var size = view.spec().num_elements()\n",
    "    var ptr = DTypePointer[dtype].alloc(size)\n",
    "    memcpy(ptr, view.unsafe_ptr().bitcast[dtype](), size)\n",
    "    return Tensor[dtype](view.spec(), ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare client/inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var open_clip = Python.import_module(\"open_clip\")\n",
    "var PIL = Python.import_module(\"PIL\")\n",
    "var requests = Python.import_module(\"requests\")\n",
    "var torch = Python.import_module(\"torch\")\n",
    "\n",
    "var tup = open_clip.create_model_and_transforms(\n",
    "    \"ViT-B-32\", pretrained=\"laion2b_s34b_b79k\"\n",
    ")\n",
    "var tokenizer = open_clip.get_tokenizer(\"ViT-B-32\")\n",
    "\n",
    "var url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "var labels = [\"cats\", \"dogs\", \"fish\"]\n",
    "var raw_image = PIL.Image.open(requests.get(url, stream=True).raw)\n",
    "var image = tup[2](raw_image).unsqueeze(0).detach().numpy()\n",
    "var text = tokenizer(labels).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from max.engine import InferenceSession\n",
    "from max.engine.tensor import EngineNumpyView\n",
    "from max.serve.kserve.client import GRPCInferenceClient\n",
    "\n",
    "var session = InferenceSession()\n",
    "var inputs = session.new_tensor_map()\n",
    "var image_tensor = numpy_to_tensor[DType.float32](image)\n",
    "var text_tensor = numpy_to_tensor[DType.int64](text)\n",
    "inputs.borrow(\"image\", image_tensor)\n",
    "inputs.borrow(\"text\", text_tensor)\n",
    "print(str(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var req_outputs = List[String](\"image_features\", \"text_features\")\n",
    "var client = GRPCInferenceClient(\"0.0.0.0:8000\", session)\n",
    "var response = client.infer(\"openclip\", \"0\", inputs, req_outputs)\n",
    "var outputs = response.get_output_tensors()\n",
    "\n",
    "var np = Python.import_module(\"numpy\")\n",
    "var img_feats = tensor_to_numpy(outputs.get[DType.float32](\"image_features\"), np)\n",
    "var txt_feats = tensor_to_numpy(outputs.get[DType.int64](\"text_features\"), np)\n",
    "fn softmax(np: PythonObject, x: PythonObject) raises -> PythonObject:\n",
    "    var z = x - np.max(x)\n",
    "    var num = np.exp(z)\n",
    "    return np.exp(z) / np.sum(num)\n",
    "\n",
    "txt_feats /= np.linalg.norm(txt_feats)\n",
    "img_feats /= np.linalg.norm(img_feats)\n",
    "var similarity = softmax(np, 100.0 * np.matmul(img_feats, txt_feats.T))\n",
    "print(\"Label probs:\\n\", similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
