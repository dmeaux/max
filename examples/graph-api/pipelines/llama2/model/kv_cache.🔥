# ===----------------------------------------------------------------------=== #
# Copyright (c) 2024, Modular Inc. All rights reserved.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions:
# https://llvm.org/LICENSE.txt
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ===----------------------------------------------------------------------=== #
"""KV cache for the Transformer."""


from max.engine import TensorMap
from tensor import Tensor, TensorShape, TensorSpec
from .llama import Llama2


@value
struct KVCacheView:
    """Non-owning view into the KV cache backing `Tensor`."""

    var spec: TensorSpec
    var ptr: DTypePointer[DType.float32]


fn cache_init(
    model: Llama2, size: Int, batch_size: Int
) -> Tensor[DType.float32]:
    return Tensor[DType.float32](
        TensorShape(
            size,
            model.hyperparams.n_layers,
            batch_size,
            model.hyperparams.n_kv_heads,
            model.hyperparams.head_dim,
        )
    )


fn cache_view(size: Int, buff: Tensor[DType.float32]) -> KVCacheView:
    var shape = buff.shape()
    return KVCacheView(
        TensorSpec(DType.float32, size, shape[1], shape[2], shape[3], shape[4]),
        buff.unsafe_ptr(),
    )


fn cache_update(
    results: TensorMap,
    name: String,
    buff: Tensor[DType.float32],
    current: KVCacheView,
    n: Int,
) raises:
    var update = results.buffer[DType.float32](name)
    var shape = buff.shape()
    var stride = shape[1] * shape[2] * shape[3] * shape[4]
    var pos = current.spec[0]
    memcpy(buff.unsafe_ptr() + pos * stride, update.data, n * stride)
