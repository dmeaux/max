# ===----------------------------------------------------------------------=== #
# Copyright (c) 2024, Modular Inc. All rights reserved.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions:
# https://llvm.org/LICENSE.txt
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ===----------------------------------------------------------------------=== #
"""Functions for lazily downloading model weights on first execution."""


import os
from pathlib import Path
from sys.ffi import external_call
from python import Python
from collections import Dict

from max.graph.quantization import (
    Float32Encoding,
    QuantizationEncoding,
    Q4_0Encoding,
    Q4_KEncoding,
    Q6_KEncoding,
    BFloat16Encoding,
)


def download_from_hf(repo_id: String, filename: String) -> Path:
    """Uses huggingface_hub from Python to resume downloads on interupt."""
    hf_hub_download = Python.import_module("huggingface_hub").hf_hub_download
    return Path(str(hf_hub_download(repo_id, filename)))


def check_exists(dict: Dict[String, String], key: String):
    """Take in a dictionary and check that the key exists. Raises an error if
    it's not found, showing the available keys.

    Args:
        dict: Dict with key and values that are both of type `String`.
        key: The key to check.
    Raises:
        An error if the key doesn't exist.
    """
    if key not in dict:
        error = key + " is not supported, choose from:"
        for item in dict:
            error += " " + item[]
        raise error


def download_replit(encoding: String) -> Path:
    models = Dict[String, String]()
    models[BFloat16Encoding.id()] = "replit-code-v1_5-3b-bf16.gguf"
    models[Float32Encoding.id()] = "replit-code-v1_5-3b-f32.gguf"
    check_exists(models, encoding)
    return download_from_hf("modularai/replit-code-1.5", models[encoding])


def download_llama2(encoding: String) -> Path:
    models = Dict[String, String]()
    models[Q4_0Encoding.id()] = "llama-2-7b-q4_0.gguf"
    models[Q4_KEncoding.id()] = "llama-2-7b-q4_k_m.gguf"
    models[Q6_KEncoding.id()] = "llama-2-7b-q6_k.gguf"
    models[Float32Encoding.id()] = "stories15M.bin"
    check_exists(models, encoding)
    return download_from_hf("modularai/llama-2", models[encoding])


def download_llama3(encoding: String) -> Path:
    models = Dict[String, String]()
    models[Q4_0Encoding.id()] = "llama-3-8b-instruct-q4_0.gguf"
    models[Q4_KEncoding.id()] = "llama-3-8b-instruct-q4_k_m.gguf"
    models[Q6_KEncoding.id()] = "llama-3-8b-instruct-q6_k.gguf"
    models[BFloat16Encoding.id()] = "llama-3-8b-instruct-bf16.gguf"
    models[Float32Encoding.id()] = "llama-3-8b-f32.gguf"
    check_exists(models, encoding)
    return download_from_hf("modularai/llama-3", models[encoding])


def download_llama3_1(encoding: String) -> Path:
    models = Dict[String, String]()
    models[Q4_0Encoding.id()] = "llama-3.1-8b-instruct-q4_0.gguf"
    models[Q4_KEncoding.id()] = "llama-3.1-8b-instruct-q4_k_m.gguf"
    models[Q6_KEncoding.id()] = "llama-3.1-8b-instruct-q6_k.gguf"
    models[BFloat16Encoding.id()] = "llama-3.1-8b-instruct-bf16.gguf"
    models[Float32Encoding.id()] = "llama-3.1-8b-instruct-f32.gguf"
    check_exists(models, encoding)
    return download_from_hf("modularai/llama-3.1", models[encoding])
