# ===----------------------------------------------------------------------=== #
# Copyright (c) 2024, Modular Inc. All rights reserved.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions:
# https://llvm.org/LICENSE.txt
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ===----------------------------------------------------------------------=== #

"""Module containing layers related to linear transformations."""

from max.graph import ops, Symbol
from max.graph.quantization import (
    Float32Encoding,
    QuantizationEncoding,
    Q4_0Encoding,
    Q4_KEncoding,
)


@value
struct Linear[encoding: QuantizationEncoding = Float32Encoding]:
    """A fully-connected layer without activations."""

    var w: Symbol

    def __call__(self, x: Symbol) -> Symbol:
        @parameter
        if encoding.id() == Q4_0Encoding.id():
            return ops.qmatmul[Q4_0Encoding](x, self.w)
        elif encoding.id() == Q4_KEncoding.id():
            return ops.qmatmul[Q4_KEncoding](x, self.w)
        elif encoding.id() == Float32Encoding.id():
            return x @ self.w

        raise "unsupported quantization encoding in Linear: " + encoding.id()

    def __rmatmul__(self, lhs: Symbol) -> Symbol:
        return self(lhs)
